{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data Challenge - NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/last_2_years_restaurant_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Steakhouses, Restaurants, Cajun/Creole]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>0</td>\n",
       "      <td>nCqdz-NW64KazpxqnDr0sQ</td>\n",
       "      <td>1</td>\n",
       "      <td>I mainly went for the ceasar salad prepared ta...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>0XVzm4kVIAaH4eQAxWbhvw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Steakhouses, Restaurants, Cajun/Creole]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>0</td>\n",
       "      <td>iwx6s6yQxc7yjS7NFANZig</td>\n",
       "      <td>4</td>\n",
       "      <td>Nice atmosphere and wonderful service. I had t...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2aeNFntqY2QDZLADNo8iQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Steakhouses, Restaurants, Cajun/Creole]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-05</td>\n",
       "      <td>0</td>\n",
       "      <td>2HrBENXZTiitcCJfzkELgA</td>\n",
       "      <td>2</td>\n",
       "      <td>To be honest it really quit aweful. First the ...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>WFhv5pMJRDPWSyLnKiWFXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Steakhouses, Restaurants, Cajun/Creole]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>0</td>\n",
       "      <td>6YNPXoq41qTMZ2TEi0BYUA</td>\n",
       "      <td>2</td>\n",
       "      <td>The food was decent, but the service was defin...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2S6gWE-K3DHNcKYYSgN7xA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Steakhouses, Restaurants, Cajun/Creole]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-08</td>\n",
       "      <td>1</td>\n",
       "      <td>4bQrVUiRZ642odcKCS0OhQ</td>\n",
       "      <td>2</td>\n",
       "      <td>If you're looking for craptastic service and m...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>rCTVWx_Tws2jWi-K89iEyw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                  name  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "\n",
       "                                 categories  avg_stars  cool        date  \\\n",
       "0  [Steakhouses, Restaurants, Cajun/Creole]        4.0     0  2015-06-26   \n",
       "1  [Steakhouses, Restaurants, Cajun/Creole]        4.0     0  2015-06-29   \n",
       "2  [Steakhouses, Restaurants, Cajun/Creole]        4.0     0  2015-04-05   \n",
       "3  [Steakhouses, Restaurants, Cajun/Creole]        4.0     0  2016-02-16   \n",
       "4  [Steakhouses, Restaurants, Cajun/Creole]        4.0     0  2016-02-08   \n",
       "\n",
       "   funny               review_id  stars  \\\n",
       "0      0  nCqdz-NW64KazpxqnDr0sQ      1   \n",
       "1      0  iwx6s6yQxc7yjS7NFANZig      4   \n",
       "2      0  2HrBENXZTiitcCJfzkELgA      2   \n",
       "3      0  6YNPXoq41qTMZ2TEi0BYUA      2   \n",
       "4      1  4bQrVUiRZ642odcKCS0OhQ      2   \n",
       "\n",
       "                                                text    type  useful  \\\n",
       "0  I mainly went for the ceasar salad prepared ta...  review       0   \n",
       "1  Nice atmosphere and wonderful service. I had t...  review       0   \n",
       "2  To be honest it really quit aweful. First the ...  review       0   \n",
       "3  The food was decent, but the service was defin...  review       0   \n",
       "4  If you're looking for craptastic service and m...  review       1   \n",
       "\n",
       "                  user_id  \n",
       "0  0XVzm4kVIAaH4eQAxWbhvw  \n",
       "1  2aeNFntqY2QDZLADNo8iQQ  \n",
       "2  WFhv5pMJRDPWSyLnKiWFXA  \n",
       "3  2S6gWE-K3DHNcKYYSgN7xA  \n",
       "4  rCTVWx_Tws2jWi-K89iEyw  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define feature variables, here is the text of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the values of the column that contains review text data\n",
    "documents = df.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'I mainly went for the ceasar salad prepared tableside.  I ate in the bar, the bartender was very nice and helpful.  I got the grilled cheese with tomato soup.  Grilled cheese was very good but the soup was nothing special.  Now the salad that i read one reviewer said the best in vegas, which is the only reason i came.  Knowing that they put anchovies in it when they prepare tableside, i was going to tell them to hold off on that once they get started.  So as im waiting for them to come up and make it, they bring it already prepared.  What is that?  The whole point of getting it is to watch it being done and see that its made fresh.  So obviously the anchovies were already in it, and since i explained i didnt want them, they made another.   I was told its a fire hazard to prepare it in the bar area so they made it on the side when i wasnt looking.  The few bites i took werent that good.  So i watch them make the 2nd salad in the hallway.  Needless to say, it was totally flavorless, ive had better dressing from newmans own, and the lettuce was in long stems, not even cut up. I was very disappointed with the salad, although the other food looked good',\n",
       "       \"Nice atmosphere and wonderful service. I had the dinner special which was a wedge salad, a petite ribeye, and desert.   \\n\\nThe salad was as expected. Nothing to jump up and down about. The petite ribeye was tasty. Just a minute over cooked, but overall it was good. The desert was ice cream and cake. As I'm not a cake eater I can't tell you about that, but the ice cream was good. \\n\\nOverall, it was a pleasant dinner.\"], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For example, I am interested in perfect (5 stars) and imperfect (1-4 stars) rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['perfection'] = df['stars'].apply(lambda x : int(x == 5))\n",
    "target = df['perfection'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the statistic of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:0.46076595353\n"
     ]
    }
   ],
   "source": [
    "print \"mean:{}\".format(target.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangtianqi/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_train, documents_test, target_train, target_test = train_test_split(documents, target, \n",
    "                                                                              test_size=0.3, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get NLP representation of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = \"english\", max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with training data\n",
    "vectors_train = vectorizer.fit_transform(documents_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vocab of tfidf\n",
    "words = vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the trained model to transform test data\n",
    "vectors_test = vectorizer.transform(documents_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar review search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_top_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the highest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"cat\", \"pig\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[::-1][:n]]  # np.argsort by default sorts values in ascending order\n",
    "\n",
    "def get_bottom_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the lowest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"mouse\", \"rabbit\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[:n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw an arbitrary review from test (unseen in training) documents\n",
    "query = documents_test[666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 5000), (243333, 5000))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the drawn review(s) to vector(s)\n",
    "vector_query = vectorizer.transform([query]).toarray()\n",
    "vector_query.shape,vectors_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity score(s) between vector(s) and training vectors\n",
    "scores = cosine_similarity(vector_query,vectors_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ \"The food is delicious every time I come here. I like my stuff very spicy.. I usually order level 25, up to level 50 and it still has taste and flavor, not overpowered by the extreme spice. They are always friendly and I've never had a bad experience.\",\n",
       "       'Love the combination of White Peach Oolong tea with Lychee jelly. Loco moco with it is perfectionnnnn',\n",
       "       'Seems like this place has gotten a majority of their negative reviews very recently... \\n\\nWe ordered a teriyaki chicken dish, the middle pieces were literally raw... We show it the waiter, he agrees, takes the whole dish back. He comes back sometime later with the same dish with the same chicken cooked. The raw chicken was sitting on a bed of cabbage n he re-cooked the chicken and put it on the same used plate. Unbelievable! \\n\\nOtherwise none of the dishes were that great...\\n\\nWe ordered a \"Popcorn Lobster\"roll... It was almost $20 for this roll... Would be a fair price if we had actually gotten lobster, however, we got some nasty crawfish bites that were fried...\\n\\nOverall rating here should\\'ve negative 10 stars...',\n",
       "       ...,\n",
       "       'This place is a must try if your looking for a breakfast/lunch place in the Southwest area!\\n\\nMy favorite dish:\\n\\n-LEMON POPPY SEED Pancakes! They are just the perfect mix! Light & fluffy just how I like! Also for the lemon flavor is not overwhelming which is a plus. Also the fresh squeezed OJ is refreshing as well!',\n",
       "       \"Chicken fried steak awesome, chocolate chip pancakes heaven service just as grandma's house!!\",\n",
       "       \"Wendy is an amazing chef and owner.  She is always so kind and happy.\\nThe food is delicious!  We love the sirloin burger sliders, tamarind soup, peppered beef cubes and red French rice.  We have been going to Wendy's Noodle Cafe since the day it opened and we are always impressed!  All is so tasty!\"], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find top 5 similar reviews\n",
    "n = 5\n",
    "similar_reviews = get_top_values(scores[0], n, documents_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our search query:\n",
      "Finally decided i would try this joint out despite the long line thats always outside. NOW i understand why people wait in line... Its pretty much worth it, ant the prices are great! I love the fact that this isnt just a burger place they have other popular options. Costumer service was pretty good too (:\n"
     ]
    }
   ],
   "source": [
    "print 'Our search query:'\n",
    "print  query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most 5 similar reviews:\n",
      "No.1\n",
      "Good food but very long time to wait in line\n",
      "No.2\n",
      "It's a long line.. Expect to wait. So we went to just ordered their Blizzard type. It's pretty good!!! Definitely we will try to get here and eat here and try their special burger\n",
      "No.3\n",
      "If you never tried it, must experience it. Great little burgers that will fill you up. 10 should be enough for a person. Good place for late night in Vegas. Opens 24/7.  Line isnt so long. Worth to try and wait for. Great for hangovers after the club.\n",
      "No.4\n",
      "Loved this place so much we went twice!!\n",
      "Dont let the long line discourage you, the wait isnt very long and its well worth it. \n",
      "The hells kitchen burger has everything you would ever want and more! We also ordered jalapeno poppers which were a little large for just two people but so good, truffle fries were fantastic. If you like beer this place is also for you so many options on tap!!\n",
      "I just wish they had one of these in Seattle!\n",
      "No.5\n",
      "The food and service is great! Expect a long wait because it's so popular but it's worth it!!\n"
     ]
    }
   ],
   "source": [
    "print 'Most %s similar reviews:' % n\n",
    "for i, reviews in enumerate(similar_reviews):\n",
    "    print 'No.%d' % (i+1)\n",
    "    print reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment: The result makes sense. These 5 comments are all positive comments and all refer to \"wait\" \"long\" and \"line\" mentioned in query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying positive/negative review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80487644503622613"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "nb_model.score(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80151698214525435"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "nb_model.score(vectors_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83580936412241658"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.score(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82732102103829852"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.score(vectors_test,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'amazing',\n",
       " u'best',\n",
       " u'awesome',\n",
       " u'thank',\n",
       " u'incredible',\n",
       " u'phenomenal',\n",
       " u'perfect',\n",
       " u'delicious',\n",
       " u'fantastic',\n",
       " u'highly',\n",
       " u'outstanding',\n",
       " u'excellent',\n",
       " u'perfection',\n",
       " u'great',\n",
       " u'heaven',\n",
       " u'favorite',\n",
       " u'notch',\n",
       " u'fabulous',\n",
       " u'perfectly',\n",
       " u'die']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key features(words) that make the positive prediction\n",
    "n = 20\n",
    "features_for_positive = get_top_values(lr_model.coef_[0], n, words)\n",
    "features_for_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'worst',\n",
       " u'horrible',\n",
       " u'bland',\n",
       " u'disappointing',\n",
       " u'rude',\n",
       " u'ok',\n",
       " u'mediocre',\n",
       " u'terrible',\n",
       " u'okay',\n",
       " u'slow',\n",
       " u'lacking',\n",
       " u'lacked',\n",
       " u'poor',\n",
       " u'awful',\n",
       " u'overpriced',\n",
       " u'meh',\n",
       " u'average',\n",
       " u'unfortunately',\n",
       " u'disgusting',\n",
       " u'tasteless']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key features(words) that make the negative prediction\n",
    "n = 20\n",
    "features_for_negative = get_bottom_values(lr_model.coef_[0], n, words)\n",
    "features_for_negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9897424517019886"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.score(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77243350018219126"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.score(vectors_test,target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: The model overfits the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important features (words) of the RFC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'best',\n",
       " u'amazing',\n",
       " u'delicious',\n",
       " u'awesome',\n",
       " u'great',\n",
       " u'love',\n",
       " u'good',\n",
       " u'vegas',\n",
       " u'bad',\n",
       " u'didn',\n",
       " u'definitely',\n",
       " u'worst',\n",
       " u'ok',\n",
       " u'place',\n",
       " u'excellent',\n",
       " u'wasn',\n",
       " u'pretty',\n",
       " u'food',\n",
       " u'just',\n",
       " u'rude']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 20\n",
    "get_top_values(rf_model.feature_importances_, n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cross validation to evaluate classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76861593,  0.76783036,  0.7746476 ,  0.768216  ,  0.77027083])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "rf = RandomForestClassifier()\n",
    "score_rf = cross_val_score(rf, vectors_train, target_train, cv=5)\n",
    "score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82481302,  0.82423408,  0.82934698,  0.82548391,  0.82566884])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "score_lr = cross_val_score(lr, vectors_train, target_train, cv=5)\n",
    "score_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8026013 ,  0.7997    ,  0.80462746,  0.80066165,  0.80201784])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "score_nb = cross_val_score(nb, vectors_train, target_train, cv=5)\n",
    "score_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use grid search to find best predictable classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'penalty': ['l1', 'l2'], 'C': [1, 10, 100, 1000], 'random_state': [1]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'penalty': ['l1','l2'],'random_state':[1]}\n",
    " ]\n",
    "lr_gridsearch = GridSearchCV(lr,param_grid, cv = 10)\n",
    "lr_gridsearch.fit(vectors_train, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 1, 'random_state': 1}\n",
      "0.824612259743\n"
     ]
    }
   ],
   "source": [
    "print lr_gridsearch.best_params_\n",
    "print lr_gridsearch.cv_results_['mean_test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
